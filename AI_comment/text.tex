%
% A simple LaTeX template for Books
%  (c) Aleksander Morgado <aleksander@es.gnu.org>
%  Released into public domain
%

\documentclass[12pt]{memoir}
\usepackage[a4paper, top=3cm, bottom=4cm]{geometry}
\usepackage[utf8]{inputenc}
\let\footruleskip\undefined
\usepackage{setspace}
\usepackage[english,spanish]{babel}
\usepackage{fancyhdr}
\usepackage[linktocpage=true]{hyperref}
\usepackage{cleveref}
\usepackage{mathptmx}
\usepackage{libertine}
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{epigraph}
\usepackage[autostyle]{csquotes} 
\usepackage[style=authoryear,backend=bibtex]{biblatex}
\usepackage[bottom]{footmisc}
\usepackage{color,soul}
\usepackage{url}
\usepackage{chngcntr}

\counterwithout{footnote}{chapter}
\setcounter{secnumdepth}{3}

\bibliography{philo}

%Title page command
\newlength\drop
\makeatletter
\newcommand*\titleM{\begingroup% Misericords, T&H p 153
\setlength\drop{0.08\textheight}
\centering
\vspace*{\drop}
{\Huge\bfseries La noción de inteligencia después de \textit{Computing Machinery and Intelligence}}\\[\baselineskip]
{\scshape una perspectiva histórica}\\[\baselineskip]
\vfill
{\large\scshape Pedro Montoto García (USC)}\par
{\large\scshape Enrique Alonso González (UAM)}\par
\vfill
{\scshape \@date}\par
\vspace*{2\drop}
\endgroup}
\makeatother

%Keywords command
\providecommand{\keywords}[2]{
	\textbf{\textit{#1: }} #2
}

\widowpenalties 1 5000
\raggedbottom

\begin{document}

\chapterstyle{southall}
\pagestyle{empty}
%\pagenumbering{}

% 1st page for the Title
%-------------------------------------------------------------------------------

\begin{titlingpage}
\titleM
\end{titlingpage}

\OnehalfSpacing



\setlength{\epigraphwidth}{0.8\textwidth}
\thispagestyle{empty}
\epigraph{\flqq\textit{Intelligence is} what is measured by intelligence tests.\frqq}{E. Boring, circa 1920, en \cite{intDefs}}

\textcolor{red}{\textbf{\hl{Revisar apendice A}}}
\textcolor{red}{\textbf{\hl{Revisar apendice B}}}
\newpage


% Not enumerated chapter
%-------------------------------------------------------------------------------
\thispagestyle{empty}
\begin{abstract}
	Este trabajo pretende estudiar en profundidad el concepto de inteligencia que describe el \textit{juego de la imitación}, también conocido como \textit{Test de Turing} en \textit{Computing Machinery and Intelligence} (\cite{Turing1950cmi}). Ofrecemos una panorámica histórica de la evolución tecnológica y filosófica que conduce a este experimento y listamos los pros y contras que el mismo tiene para la detección de inteligencia general. Para ello analizamos la propuesta de Turing para artefactos inteligentes y la relacionamos con los avances tecnológicos desde la publicación de dicho artículo. Se presenta como conclusión la caracterización experimental de los Test de Turing y derivados del mismo, así como sus pros y contras, y la necesidad de avanzar hacia un mejor modelo de experimentos. Hemos añadido apéndices relatando aspectos secundarios de la evolución de la maquinaria de cómputo y la psicología que ayudan a comprender el contexto en el que este artículo fue desarrollado y su evolución posterior.
\end{abstract}

\nocite{Nilsson2009}

\keywords{Palabras clave}{Historia de la Inteligencia Artificial, Filosofía de la Inteligencia Artificial, Alan Turing, Ciencias Cognitivas, Cibernética}

\begin{otherlanguage}{english}
\begin{abstract}
\end{abstract}
\end{otherlanguage}

\keywords{Keywords}{History of Artificial Intelligence, Philosophy of Artificial Intelligence, Alan Turing, Cognitive Sciences, Cybernetics}

\newpage
\thispagestyle{empty}


% If the chapter ends in an odd page, you may want to skip having the page
%  number in the empty page


%Finally, include the ToC
\DoubleSpacing
\begin{KeepFromToc}
  \tableofcontents
\end{KeepFromToc}
\thispagestyle{empty}
\OnehalfSpacing
\newpage

% Define Page style for all chapters
\pagestyle{fancy}
% Delete the current section for header and footer
\fancyhf{}
% Set custom header
\cfoot{\thepage}
% Set arabic (1,2,3...) page numbering
\pagenumbering{arabic}

% First enumerated chapter
%-------------------------------------------------------------------------------
\chapter{Breve historia de la Inteligencia Artificial}

\epigraph{\flqq I propose to consider the question, ``Can machines think?''\frqq}{\cite{Turing1950cmi}}

Todo desarrollo relativo a la Inteligencia Artificial comienza con una pregunta de apariencia simple, \textit{¿es posible construir algo que pueda pensar?}, o cuestiones anejas como  \textit{¿es posible construir algo vivo?} o \textit{¿es posible construir algo que resuelva cualquier problema matemático?}, que en realidad presentan otras muchas cuestiones asociadas. Este tipo de ideas no es en absoluto reciente ni mucho menos. La idea de la Inteligencia Artificial ha existido en diversas formas durante la historia del pensamiento occidental, al menos desde la Grecia clásica, en mitos, leyendas, historias, especulación y autómatas mecánicos y que, a favor o en contra, intentan dar una respuesta final a esta especie de sueño colectivo. Trataremos de ofrecer un recorrido histórico que nos permita entender el contexto en el que \cite{Turing1950cmi} fue concebido. En este primer epígrafe justificamos el interés del tema tratado en el artículo a analizar y esbozamos una historia de la idea de creación de objetos inteligentes.

En las primeras leyendas griegas de las que tenemos constancia, alrededor del siglo V a.C., se tratan entre otros temas las estatuas de Pigmalión traídas a la vida por Afrodita, diosa de la vida y del amor, y la historia de Hefesto, dios de la forja, que era capaz de construir ayudantes dorados para los dioses. De todo esto nos llega noticia a través de la \textit{Política} de Aristóteles, que crea uno de los primeros ejemplos de ciencia ficción político-social, planteando la cuestión de qué ocurriría si tuviésemos \textit{máquinas/autómatas/seres artificiales} inteligentes:

\begin{quotation}
Pues si cada uno de los instrumentos pudiera cumplir por sí mismo su cometido obedeciendo órdenes o anticipándose a ellas, si, como cuentan de las estatuas de Dédalo o de los trípodes de Hefesto, de los que dice el poeta que entraban por sí solos en la asamblea de los dioses las lanzaderas tejieran solas y los plectros tocaran la cítara, los constructores no necesitarían ayudantes ni los amos esclavos. \parencite[Aristot. Pol. 1.1253b]{aristotlePolitics}
\end{quotation}

Prosiguiendo, el Talmud, compilado entre los siglos I y VI, habla de \textit{golems} creados de tierra a los que hombres santos y doctos podrían infundir de vida. En el siglo XII el mallorquín Ramon Llull construye un conjunto de discos de papel que teniendo como base la lógica escolástica y convenientemente combinados y rotados permitirían dirimir cualquier discusión teológica, sistema que llamó \textit{Ars Magna}. En algún momento entre finales del siglo XV ó principios del XVI Leonardo da Vinci crea unos esquemas para un robot-caballero que sería capaz de sentarse, levantarse y mover los brazos manipulado, eso sí, por un humano\footnote{Éste robot se presentó funcionando en una fiesta de la época en la corte de Venecia en 1495 organizada por Ludovico Sforza, y más recientemente un empresario llamado Mark Elling Rosheim reconstruyó los diseños de Leonardo, probando que los mismos eran sensatos y funcionales.}. 

En el siglo XVII se desarrolla, debido al auge del racionalismo y las ideas humanistas, la idea de que todo puede ser explicable mediante métodos mecánicos y matemáticos\footnote{Verbigracia citamos el título de la publicación de Isaac Newton \textit{Principios matemáticos de la filosofía natural} cuyo tercer tomo lleva por título \textit{El sistema del mundo}}, incluidos los seres vivos. Se puede decir incluso que hasta ésta época, desde la Grecia clásica, vida e inteligencia sólo podía ser algo otorgado por dioses u otros seres omnipotentes más allá del universo físico, al darse que cualquier creación humana no puede superar una imitación de la vida que la divinidad otorga. Hobbes, en este mismo siglo en su \textit{Leviathan}, contempla la posibilidad de crear un ingenio mecánico que se comporte como un animal, pues todos los órganos para él tienen paralelismos con la mecánica: ``el corazón no es más que un muelle, los nervios son cuerdas'' y pasajes similares aparecen a lo largo de su obra. Descartes, por el contrario, creía que las máquinas serían incapaces de pensamiento real pues sólo están formadas por materia y sería imposible dotarlas de mente ya que la \textit{res cogitans} es inmaterial. Algunos pensadores creen ver en Leibniz un avance de la Inteligencia Artificial ya que, al igual que Hobbes, concebía que todo lo que hace la mente son computaciones, en \textit{De arte combinatoria}. 

En el siglo XVIII Jacques de Vaucanson presenta un autómata que es capaz de simular un pato vivo en algunos de sus aspectos, construido mediante un armazón metálico adornado con plumas de pato y componentes de relojería y mecánica, que era capaz de comer grano, beber y ``digerir'' (En realidad el producto de la digestión ya estaba en el interior del pato para la simulación). Jacques de Vaucanson también es el inventor de las primeras tarjetas perforadas entendidas como contenedoras de programas, secuencias de acciones, para entes mecánicos. Éstas tarjetas se usarán en la ``programación'' de telares mecánicos en el siglo XIX y a principios del siglo XX podremos ver ya máquinas calculadoras que permitían hacer operaciones aritméticas usando estas tarjetas como entrada y salida de información. También en el siglo XVIII se creó el ``Turco mecánico'', un autómata que podía jugar al ajedrez como un maestro y que como exhibición del mismo fue enviado de gira por las cortes de Europa de la época retando y ganando a soberanos y estrategas. Más tarde se supo que éste ``autómata'' debía su genialidad a un maestro de ajedrez humano que se ponía en su interior en cada partida, una maniobra que continúa siendo usada hoy para entrenar o suplir las capacidades que aún no sabemos construir en máquinas.

A partir del siglo XIX comenzamos a ver por doquier obras de teatro, narraciones y películas que hablan del \textit{qué ocurriría} si las máquinas pudiesen pensar o actuar como humanos\footnote{Como veremos, entre el pensar y el actuar como humanos se puede adoptar una postura completamente funcionalista, como la que adopta Turing, estableciendo una diferencia entre la percepción de un acto inteligente y el proceso hipotético subyacente que lo hace posible, el pensamiento.}. Es evidente, por tanto, que muchos de los problemas que plantea el nacimiento de la IA no son nuevos. El siglo XIX ve el renacer de la lógica como disciplina académica en trabajos como \textit{The Laws of Thought} de George Boole o el \textit{Begriffsschrift} de Gottlob Frege, que son el antecesor directo de las ciencias y maquinaria de la computación.

Para la descripción de las condiciones técnicas en las que se gestó \parencite{Turing1950cmi} comenzaremos por el cerebro, órgano que tradicionalmente se considera como fuente de los comportamientos inteligentes. 

Luigi Galvani descubrió, en el siglo XVIII, que las señales neuronales son esencialmente de naturaleza eléctrica al experimentar con corrientes eléctricas y músculos de rana. La disciplina que estudia la ``maquinaria'' del cerebro, la neurociencia, fue inaugurada a principios del siglo XX por Camilo Golgi y Santiago Ramón y Cajal. Camilo Golgi había inventado un método de contraste que permitía distinguir la estructura del tejido cerebral y sus ramificaciones mediante microscopio, mientras que Ramón y Cajal, continuando el uso de éste método creó la teoría de que el tejido cerebral no se componía de una malla de hilos neuronales, sino que dicho tejido estaba formado por células contiguas pero separadas entre sí, las neuronas. 

En \parencite{mcCullochPitts} se crea el primer modelo computacional bioinspirado de neuronas artificiales  y se demuestra cómo podían usarse dichas neuronas artificiales para calcular funciones lógicas básicas: las neuronas reciben un número de señales de otras neuronas y emiten señal si la intensidad total sobrepasa un umbral interno, es decir, las neuronas pueden expresarse mediante una función de enteros en enteros\footnote{Una crítica a este sistema \parencite{newmind} afirma que las señales de entrada y salida del sistema de una neurona pueden ser binarias, pero es necesario un sistema en el que se apliquen efectos cuánticos para poder simular completamente ésta función entre conjuntos binarios.}, en concreto del tipo $f: \lbrace 0, 1\rbrace^n \rightarrow \lbrace 0, 1\rbrace$. El propio Turing \parencite{turingComputableNumbers} describe un procedimiento para calcular funciones entre enteros, del que hablaremos en la siguiente sección, que McCulloch y Pitts demostraron equivalente al poder de computación de sus neuronas artificiales, avanzando también sistemas de aprendizaje automático.

Dentro del campo psicológico el trabajo de Turing se encuentra como precedente del \textit{funcionalismo} \parencite{sep-functionalism}, en tanto asume que el proceso mental, aunque imposible de observar directamente, es importante para la generación de comportamiento inteligente. El \textit{funcionalismo} es una escuela de pensamiento psicológico que trata de superar el \textit{conductualismo}, para el cual todos los comportamientos conscientes son el resultado de un condicionamiento inconsciente, mediante refuerzo o inhibición de acuerdo al resultado que se ha obtenido después de cierto comportamiento (i.e. comportamientos con resultado positivo para el actor se promueven y viceversa). Antes de la aparición del conductualismo la única forma que que se aceptaba para la elaboración de teorías psicológicas era la introspección, sistema que tendía a provocar que los únicos datos que llegaban a publicarse fuesen los que concordaban con las teorías populares en cada grupo de investigación \parencite[p.13]{modernAI}.

La aparición de grupos de interés para la creación de máquinas inteligentes provocará que se creen grupos de estudio comunes entre psicólogos, neurocientíficos y científicos de la computación, lo que se ha dado en llamar \textit{ciencias cognitivas}. Relatamos su origen en el apéndice \ref{cognitiveHistory}, ya que no es tan relevante para la elaboración del argumento de Turing, pero realmente importante en la evolución posterior como integración de esfuerzos de la IA, la neurociencia y la psicología.

Tenemos por tanto una arquitectura general de lo que suponemos la base de los comportamientos inteligentes y hemos identificado los elementos mínimos del sistema, las neuronas, estableciendo una relación clara con la disciplina de la computación y la comunicación\footnote{En concreto, el hecho de que ambos sistemas, neuronas y chips electrónicos, estén basados en señales eléctricas y binarias. La publicación en 1949 de \textit{A mathematical theory of Communication} por Warren Weaver, fundador de la cibernética, y Claude Shannon, que inaugura la cuantificación (i.e. la reducción a señales cuantizadas o discretas, que en última instancia pueden ser binarias) de la información contenida en un mensaje, es clave para entender esta relación.}, por lo que dentro de la interpretación mecanicista habitual en la época sería suficiente estudiar sus relaciones y establecer un modelo matemático para obtener un sistema que nos permitiese simular el objeto de estudio. Es evidente, en retrospectiva, que ni el conocimiento ni la tecnología de la época eran suficientes para la simulación de un cerebro o de un sistema cognitivo completo, sin embargo la confluencia de estas ideas ha dado fruto en numerosas tecnologías y nuevos campos de estudio.

En definitiva la IA trata de \textit{construír y estudiar} los mecanismos que producen, por un lado, comportamientos o pensamiento de tal forma que se alineen, por otro lado, con unos criterios bien de racionalidad ideal o bien de semejanza con lo humano \parencite[p.5]{modernAI}, tal que así:
\begin{center}
\begin{tabular}{l || c | c}
  Objetivo & Pensar & Actuar \\
 \hline
 \hline
 Racional & Leyes del Pensamiento & Agentes Racionales \\
 \hline
 Humano & Modelado Cognitivo & Test de Turing \\
 \hline
\end{tabular}
\end{center}

Así, un sistema capaz de \textit{Pensar Racionalmente} debería ser capaz de realizar inferencias correctas a partir de datos dados de acuerdo a sistemas de lógica proposicional, i.e. inferencias inescapables de acuerdo a las supuestas leyes del pensamiento, en el estilo inaugurado por Boole. Un sistema capaz de \textit{Actuar Racionalmente} elabora en éstas leyes del pensamiento un procedimiento de decisión que le permite en toda situación actuar de tal manera que la situación planteada y la decisión tomada deben estar en una relación de consecuencia lógica desde unos principios de decisión racional. Sin embargo, las decisiones tomadas por humanos suelen tener desviaciones e inconsistencias respecto a lo racional \parencite{framingKahnemanTversky}, por lo tanto presuponemos que los \textit{Pensamientos Humanos} no siguen completamente las leyes de la lógica y es necesario establecer un modelo que los describa completamente. Como es imposible, por el momento, observar directamente los sistemas que dan lugar a las decisiones, se hace imperativo el establecimiento de técnicas que permitan averiguar la relación entre los actos observados y el pensamiento que suponemos hay detrás de los mismos. El Test de Turing se encuadra en la observación de dichos actos y, aunque supone que existe una relación entre pensamiento y acto, no nos permite investigar en profundidad, per se, la estructura del pensamiento, como veremos en el apartado \ref{intelligence}.

Siendo los humanos los únicos seres con los cuales actualmente podemos compartir pensamientos, a través del lenguaje, no llega a ser una sorpresa que sea el único camino que podemos tomar para la detección de Inteligencia Artificial un artefacto (concepto que exploraremos en el apartado \ref{construct}) es inteligente si los humanos lo designamos como inteligente en la realización de una tarea de forma relativa a la realización de la misma por parte de un humano, siendo las descripciones de la racionalidad una idealización del proceso de toma de decisiones humano. O, dicho de otra forma, no podemos afirmar ni negar que exista inteligencia detrás de las acciones humanas, pero sí podemos afirmar que existen comportamientos designados como inteligentes. Por tanto, creemos que la caracterización de inteligencia como una cualidad ideal es contraproducente para los objetivos de la Inteligencia Artificial, siendo únicamente identificables los actos inteligentes para un modelo mental subjetivo de la realidad que un observador de dicho acto posee. Se puede decir, resumiendo, que a falta de una descripción de la inteligencia en sí ésta es esencialmente \textit{performativa}. Ahondaremos en este tema en el apartado \ref{intelligence}, ya que es fundamental para entender el Test de Turing.

\chapter[La base física de la IA: ¿Qué entendemos por construir?]{La base física de la IA: \\ ¿Qué entendemos por construir?}
\label{construct}
\epigraph{``\textit{Intelligence is} the ability to use optimally limited resources – including time – to achieve goals.''}{Ray Kurzweil, 2000, en \parencite{intDefs}}

Para la construcción de inteligencia precisamos, por tanto, definir qué entendemos por construcción. Esto presenta un número de problemas, como veremos, que no entran por completo en el alcance de este trabajo, pero creemos que conviene reflejar el cambio de concepto que se ha dado en el último siglo, aunque los grupos de tecnólogos y científicos (ingenieros, matemáticos, biólogos, psicólogos y científicos sociales) que trabajan en Inteligencia Artificial no suelan tenerlo en cuenta. 

Creemos que esta introducción es necesaria para despojar las ideas sobre artefactos inteligentes del misticismo que las rodea, por tanto es necesario definir con precisión qué entendemos por ``construir'' (o ``máquina'') y por ``pensar''. En palabras de Turing:

\begin{quotation}
This should begin with definitions of the meaning of the terms ``machine'' and ``think''. The definitions might be framed so as to reflect so far as possible the normal use of the words, but this attitude is dangerous, If the meaning of the words ``machine'' and ``think'' are to be found by examining how they are commonly used it is difficult to escape the conclusion that the meaning and the answer to the question, ``Can machines think?'' is to be sought in a statistical survey such as a Gallup poll\footnote{Una empresa americana de investigación en opinión pública creada en 1930.}. \parencite[apartado 1]{Turing1950cmi}
\end{quotation}

Normalmente definimos artefacto (\cite[apartado 2.5]{sep-technology}; \cite[apartado 4]{sep-artifact}) como una entidad en la que algunas o todas sus propiedades preexisten en la intencionalidad de un autor, siendo necesaria la preexistencia del autor naturalmente. Restringiremos la definición de entidad a que se trata de un objeto material limitado en el espacio que podemos designar con un nombre, aunque que es un problema mucho más amplio que el alcance de este trabajo, perteneciente a las disciplinas de la metafísica y la epistemología. Por tanto, una entidad dada es un artefacto si éstas propiedades existen en la descripción dada desde la intención del autor y son aceptadas como válidas en la descripción de lo construido por el autor, i.e.\ el autor determina unas propiedades necesarias desde su intención al crear el objeto, que guiarán el proceso de construcción, y valida que dicho objeto posee las características que se esperaba del mismo.

De acuerdo con la terminología relativa a la Filosofía de la Tecnología, ``por \textit{tecnología} se entiende un conjunto de conocimientos de \textbf{base científica} que permiten describir, explicar, diseñar y aplicar soluciones técnicas a problemas prácticos de forma sistemática y racional'' \parencite[p. 2]{quintanillaRef}. Al existir el objetivo de resolver un problema práctico se entiende que la intencionalidad de dicha tecnología es resolver el citado problema, por lo tanto se define la Inteligencia Artificial como una ciencia cognitiva (ver apéndice \ref{cognitiveHistory}) cuyo objeto de estudio son los sistemas que generan comportamientos inteligentes (por ejemplo, los seres humanos). La Inteligencia Artificial obtiene así conocimiento científico que se emplea en crear una \textit{tecnología} asociada con el objetivo de construir sistemas técnicos o artefactos que puedan comportarse de forma inteligente, tecnología que en general se conoce también como Inteligencia Artificial.

Aristóteles, en su \textit{Física} incluye una definición similar para la diferencia entre los ``productos naturales'' que se generan por sus propios impulsos internos mientras que los ``productos artificiales'' precisan de una intencionalidad humana. Avicena criticaba en la edad media que la alquimia jamás podría conseguir ``sustancias genuínas'' como las presentes en la naturaleza precisamente por ser un constructo con intencionalidad humana \parencite[apartado 1.1]{sep-technology}. En este caso, para mantener el debate cerrado en torno a lo que nos proponemos definir, i.e.\ lo que es un constructo idóneo para la Inteligencia Artificial, asumiremos que no existe autor en los entes naturales y que son generados mediante procesos carentes de intencionalidad, es decir, asumimos que no existe ningún creador de los entes naturales o, de existir, no podemos saberlo.

En consecuencia, la diferenciación natural-artificial es problemática. Los avances más recientes en biología, química e Inteligencia Artificial y las promesas de avances futuros nos llevan en última instancia que lo ``artificial'' podría diferir sólamente de lo ``natural'' en una cuestión de proceso, lo que podría convertir la dicotomía ``natural''-``artificial'' en vacua: Si no podemos distinguir natural de artificial sin conocer el proceso que ha generado la entidad en cuestión y las entidades generadas por procesos ``naturales'' o ``artificiales'' son indistinguibles, observar dichas entidades antes de conocer el proceso impide distinguir cuál es ``natural'' o ``artificial'' a menos que los etiquetemos arbitrariamente. Distinciones aún más sutiles agudizan el problema: ¿una persona nacida por fecundación in-vitro, clonada o cesárea ha nacido por un proceso natural o artificial?, ¿podemos considerar las personas que demuestren inteligencia y hayan nacido mediante métodos que aparentemente son \textit{no naturales} Inteligencia Artificial? Turing anticipa este problema y afirma:

\begin{quotation}
Finally, we wish to exclude from the machines men born in the usual manner. [...], for it is probably possible to rear a complete individual from a single cell of the skin (say) of a man. To do so would be a feat of biological technique deserving of the very highest praise, but we would not be inclined to regard it as a case of ``constructing a thinking machine.'' This prompts us to abandon the requirement that every kind of technique should be permitted. \parencite[apartado 3]{Turing1950cmi}
\end{quotation}

La razón de esta problemática es que las cualidades del artefacto que lo hacen ``natural'' o ``artificial'' no son inherentes al mismo una vez el sistema técnico para la imitación ha sido lo suficientemente perfeccionado. Este hecho será de especial relevancia cuando comentemos el \textit{juego de la imitación}, y Turing ya anticipa ésta crítica limitando lo que pueda afirmarse como máquina inteligente construida.

Por tanto, la distinción ``inteligencia natural''-``inteligencia artificial'' sólo podría darse en dos casos, al tratarse de una cualidad sólo observable en su manifestación como actos inteligentes: i.e. dado el caso de que ambas entidades sean indistinguibles por sus actos inteligentes, o bien se conoce el proceso de creación de ambas entidades, o bien se conoce que ambos tienen un asentamiento material diferente, uno de los cuales ha sido identificado como natural, antes de su evaluación como inteligentes.

Conviene resaltar que todas las referencias que se han podido compilar para este trabajo no adoptan una postura respecto a las bases filosóficas de la distinción natural-artificial o de la teleología de los componentes de la inteligencia, y la proposición de Turing parece demasiado arbitraria dados los avances en ingeniería genética y computación basada en soportes biológicos. La mayoría de la literatura se limita a presentar diferentes modelos matemáticos equivalentes a la \textit{Máquina de Turing}, que explicaremos a continuación.

Alan Turing formaliza \parencite{turingComputableNumbers} una idea intuitiva de máquina capaz de realizar cálculos \footnote{Que Turing usaría, probablemente sin formalizar, en sus implementaciones de las \textit{Bombes}, unas de las primeras máquinas de cálculo eléctricas que fueron usadas para acelerar el descifrado de mensajes alemanes en la Segunda Guerra Mundial. Sobre la manera en la que el artefacto precede a su teorización en la ciencia de la computación puede leerse en \parencite[apartado 1]{alonso}.}, que hoy conocemos generalmente como \textit{Máquina de Turing}. Dicha máquina desprovista del aparataje formal matemático consiste en una cinta en la que se pueden escribir y sobreescribir símbolos, teniendo capacidad infinita numerable para símbolos y siendo el símbolo la unidad de lectura y escritura, y un dispositivo de máquina de estados que define una función parcial de aplicación continua hasta que se alcanza un estado de parada. Esta función nos dice que si la máquina se encuentra en un estado $x_{t}$ y lee en la cinta un símbolo $s_i$: escribirá en esa misma posición un símbolo $s_o$ (que puede ser igual a $s_i$), se moverá una posición adelante o atrás, y se moverá al estado $x_{t+1}$, o se quedará en $x_{t}$ según el ``programa'' descrito por la función. La definición de función recursiva toma pues, la forma de esta máquina de estados con memoria sobreescribible. 

Se dice que un computador u otro modelo de función computable es Turing-completo si en caso de poder ser dotado con una memoria infinita, que por motivos prácticos es imposible en computadores no teóricos, fuese capaz de calcular las mismas funciones que una máquina de Turing.

Describimos pues la convención actual del artefacto computacional como soporte físico de la Inteligencia Artificial, derivada del artículo de \cite[apartados 4 y 5]{Turing1950cmi} que se limita a describir un ``computador digital'' que podría llevar a cabo las mismas tareas que un ``computador humano\footnote{Antes de la aparición del computador doméstico se llamaba \textit{computers} a las personas que realizaban cómputos, aunque en general sólo en contextos científicos.}'' dotado de un libro de reglas de las cuales no se puede desviar y un suministro ilimitado de material de escritura. Esencialmente, el computador humano es el responsable de leer, ejecutar y controlar el estado del \textit{programa} escrito en el libro, usando el papel para recordar los datos que sean necesarios, lo que es equivalente a la \textit{arquitectura de von Neumann} para computadores eléctricos. Dicha arquitectura es equivalente a una máquina de Turing, siendo sus limitaciones respecto al modelo teórico esencialmente tecnológicas (i.e. como ya hemos dicho, es imposible construír una memoria infinita como la que la máquina teórica posee, vide \cite[apartado 4]{Turing1950cmi}).

Describimos aquí el equivalente moderno de la propuesta de Turing, que esencialmente no posee capacidades adicionales salvo ser más rápido y tener una menor tasa de fallos, lo que en la jerga del ingeniero en computación sería la ``infraestructura'', y que se compone normalmente de estos cuatro elementos:

\begin{itemize}
	\item En el núcleo del artefacto tenemos el soporte físico de cómputo: hablamos generalmente de una máquina de cómputo de propósito general con procesador aritmético-lógico y memoria, que contendrá datos y programa de acuerdo a la arquitectura von Neumann, o más recientemente, de varias de éstas máquinas conectadas mediante una red de datos (llamado procesamiento distribuído) o funcionando sobre una memoria compartida (llamado procesamiento paralelo).
	\item Éste elemento se suele cargar con un sistema operativo que establece una capa de abstracción sobre los elementos físicos para que los programadores puedan usar todos los componentes de forma simple y eficiente, ya que se encarga también de otorgar el control de recursos físicos a programas.
	\item Sobre los sistemas operativos se opera mediante lenguajes de programación, que consisten en abstracciones sobre los sistemas del mismo que alcanzan al sistema físico de cómputo y que al mismo tiempo ofrecen una manera de expresar algoritmos. Cada lenguaje ofrece diferentes estructuras computacionales que los hacen más adecuados para expresar un tipo de algoritmo u otro, aunque todos suelen tener la misma capacidad teórica, esto es, la Turing-completitud.
	\item En última instancia tenemos los algoritmos y estructuras de datos que nos permiten resolver el problema que estemos tratando. Ésta es la parte esencial del sistema que identificamos como Inteligencia Artificial, ya que todos los sistemas actuales poseen pequeñas variaciones de los sistemas precedentes siendo los cambios en algoritmia los más relevantes hoy en día.
\end{itemize}

Como vemos, cada parte del sistema de cómputo establece abstracciones sobre el elemento anterior dando lugar a la posibilidad de construir elementos más complejos: los algoritmos se escriben en lenguajes de programación, que se compilan o interpretan para una máquina de cómputo y un sistema operativo. La ventaja consiste en que los lenguajes de alto nivel dan facilidades para escribir algoritmos más complejos que los conjuntos de instrucciones mínimos de cada máquina particular. A su vez los sistemas operativos generalizan funcionalidades sobre maquinarias diferentes, por ejemplo, una única forma de interacción para los diferentes discos duros y sistemas de archivos. Cada una de estas partes puede considerarse como un problema en sí mismo, lo que ayuda a la simplificación de su resolución en conjunto, y a la división en tareas de los grupos de investigación. Sobre la evolución de las máquinas de cómputo modernas puede leerse el apéndice \ref{compHis}. De la relación entre estos elementos y sobre las necesidades que provocan su aparición puede leerse \parencite{wiki:computerhistory}.

Para el futuro de la computación se consideran hoy relevantes 3 tecnologías que podrían sustituir la computación electrónica: computadores fotónicos, cuánticos y bioquímicos. La expansión de la tecnología electrónica mediante elementos ópticos, con la promesa de mayor velocidad al ser las interacciones entre fotones más rápidas que las interacciones entre electrones. También la computación cuántica, que utiliza los fenómenos a nivel de partícula atómica, lo que permite la paralelización masiva de las operaciones de cálculo. Y, finalmente, la computación basada en ADN y biología molecular, basada en las interacciones químicas entre proteínas y ácidos o en los intercambios químicos entre células como en las sinapsis neuronales. Estas tecnologías tienen una relación inherente con la base física o biológica de los seres vivos, y aunque no resulten productivas para los problemas de computación actuales \footnote{Por ejemplo, se asume que la computación basada en elementos biológicos resulta más lenta que su equivalente electrónico pero permite el procesado paralelo en una escala mucho mayor, lo que puede ser también una propiedad de la computación cuántica según la implementación que siga.} podrían darnos esa capacidad de imitación a todos los niveles que mencionamos anteriormente.


\chapter{La definición de inteligencia}
\label{intelligence}

\epigraph{``Viewed narrowly, there seem to be almost as many definitions of
intelligence as there were experts asked to define it.''}{R. J. Sternberg, citado en \cite{intDefs}}

Entender lo que es inteligencia es un apartado importante aunque de difícil solución en el campo de la Filosofía de la Inteligencia Artificial, tal y como se puede comprobar en la diversidad y número de definiciones en \parencite{intDefs}. En primer lugar, afirmar que existe una ``inteligencia'' como entidad en el mundo nos parece un platonismo peligroso, al no poder ésta observarse directamente como veníamos avanzando, y por ello hemos propuesto reemplazarla por ``comportamientos inteligentes relativos a tareas para las que es necesaria inteligencia'', precisamente como hace Turing. ``Inteligencia'', como venimos comentando, no es predicable directamente de agentes sino que, a través comportamientos que califican a dicho agente como inteligente, usamos esta palabra a modo de abreviatura que engloba todos estos actos \parencite{diamantAdvancesAI}. Turing describe la inteligencia de forma similar en su \textit{juego de la imitación}.

\section[\textit{Computing Machinery and Intelligence}: El juego de la imitación]{\textit{Computing Machinery and Intelligence}: El juego de la imitación}
\label{computingmachineryandintelligence}

Pasamos ahora a comentar el artículo que da título a este trabajo, históricamente la fundación y guía \parencite{turingHarmful} de la investigación rigurosa hacia máquinas con comportamientos inteligentes, \textit{Computing Machinery and Intelligence}. Turing define por primera vez un método de detección no formal pero reproducible de lo que es un comportamiento inteligente. Aunque dicho artículo ha ido perdiendo relevancia en las ciencias de la computación a medida en que éstas se han ido acercando a la resolución de problemas concretos en lugar de la creación de inteligencia general, sigue siendo un artículo vigente en investigación filosófica.

En resumidas cuentas, Turing enuncia las reglas del juego que permitiría descubrir si una máquina está pensando o no. Este juego consiste en: 
\begin{itemize}
    \item Se escogen 3 sujetos humanos, una mujer, un hombre y un interrogador.
    \item El interrogador tiene el objetivo de adivinar quién es el hombre y quién la mujer. Turing no define el sexo del interrogador, aunque se refiere a ``él'' suele interpretarse que es símplemente por economía de lenguaje.
    \item El hombre debe convencer al interrogador de que es una mujer.
    \item La mujer ha de ayudar al interrogador a tomar la decisión correcta.
    \item Los participantes no deben poder verse.
    \item Los canales de comunicación deben de estar anonimizados de tal forma que no den pistas de quién es quien. Se sugiere comunicación únicamente escrita.
\end{itemize}

Seguidamente pasa a considerar qué ocurriría si sustituyésemos al hombre por una máquina capaz de realizar conversaciones imitando a humanos, i.e. la máquina debe convencer al interrogador de que es una mujer humana. En todo caso, el valor del juego de la imitación es que define un experimento para la detección de un tipo de comportamientos inteligentes, la habilidad de entender y responder a las interacciones en una conversación a 3 bandas.


Hay un punto que suele escapar a las discusiones sobre este artículo sobre el que nos gustaría llamar la atención y es que Turing explícitamente dice:
 
\begin{quotation}
``Will the interrogator decide \textbf{wrongly as often} when the game is played like this as he does when the game is played between a man and a woman? These questions replace our original, \textit{Can machines think?}''  \parencite[apartado 1]{Turing1950cmi}
\end{quotation} 

Es decir, el juego no trata de identificar \textbf{siempre} a la máquina como humana sino que los errores de identificación de un humano entre mujer y hombre sean estadísticamente parecidos a los que se cometan en la identificación entre mujer, hombre o máquina. Si un hombre humano tratando de imitar una mujer falla, algo que no está fuera de lo concebible, ¿deja de ser inteligente o no? Por ello se hace esta distinción estadística. Es decir, Turing acepta el error en la identificación y lo hace parte de la prueba, siendo el error en asignación de objetos a categorías inherente a la cognición humana, por ser éste un proceso subjetivo \parencite{lakoff}. También, comúnmente se considera que la interpretación correcta del juego no consiste en identificar la máquina como mujer, sino como humana símplemente y sin embargo, el hecho de que al interrogador no se le indique que podría estar interrogando a una máquina tiene consecuencias tan profundas que podría considerarse un juego completamente diferente \parencite[apartado 2]{turingHarmful}. Dado que la interpretación estándar considera irrelevante el sexo de los participantes \parencite[apartado 3.1]{sep-turing-test}, usaremos también esta interpretación.

Turing pasa después a describir las máquinas que podrían ser programadas para participar en el test, que salvo mejoras tecnológicas se corresponden con el nivel máquina de la arquitectura de computador digital que describimos en el epígrafe \ref{construct}. El resto de niveles de abstracción, como ya hemos explicado, facilitan la implementación del algoritmo proveyendo abstracciones sobre la máquina básica de cómputo pero no pueden aumentar las capacidades teóricas de la máquina. Por analogía, de la misma manera que al realizar deducciones matemáticas no partimos obligatoriamente del concepto de número: el matemático en general se apoya en abstracciones y teoremas ya demostrados. Turing indica que lo relevante en éste constructo no es la máquina en sí, sino el algoritmo que produce los comportamientos inteligentes: 

\begin{quotation}
``But in view of the universality property we see that either of these questions is equivalent to this, ``Let us fix our attention on one particular digital computer C. Is it true that by modifying this computer to have an adequate storage, suitably increasing its speed of action, and providing it with an appropriate programme, C can be made to play satisfactorily the part of A in the imitation game, the part of B being taken by a man?'''' \parencite[apartado 5]{Turing1950cmi}
\end{quotation}

Turing a continuación anticipa una serie de 9 objeciones, numeradas, que impedirían la construcción de dicha máquina, que reproducimos aquí agrupándolas en tres grandes categorías y actualizando las críticas a dichas objeciones (reflejamos el número en el artículo en negrita). Primera categoría, ``La máquina no puede poseer cierta característica humana'': 

\begin{enumerate}
    \item[\textbf{1}] Las máquinas carecen de alma.
    \item[\textbf{2}] Las consecuencias de la máquina inteligente son temibles ya que el hombre no debe ser sobrepasado (Interpretado literalmente por Turing como ``El ser humano debe estar por encima de todas las cosas'').
    \item[\textbf{4}] Las máquinas no pueden tener consciencia ni sensibilidad.
    \item[\textbf{5}] Las máquinas no pueden X, siendo X una cualidad humana como ``amar, aprender, ser el sujeto de su propio pensamiento, tener errores, etc.''.
    \item[\textbf{6}] Ada Lovelace, en sus notas sobre el motor diferencial de Babbage, dice que la máquina ``no puede hacer otra cosa que aquella que sepamos ordenarle cómo hacer, mas no tiene pretensión de generar nada por sí misma'', es decir, carecen de creatividad.
    \item[\textbf{9}] Las máquinas no pueden tener Percepción Extra-Sensorial.
\end{enumerate}

Estas objeciones son respondidas por Turing con contraargumentos del tipo ``en realidad, no se puede saber que las máquinas no puedan tener, o incluso que los humanos tengan dicha característica''. Consideramos, más formalmente, que 1, 2, 4 y 9 no afectan al test al ser éste funcionalista\footnote{Una de las pocas alternativas a 4 es caer en el solipsismo, asumiendo que una máquina o humano que pase el test (intercambiables, recordemos) puede no ser consciente mientras que uno mismo lo es.} y las críticas estar fundamentadas en supuestas propiedades de la esencia humana cuya existencia no ha sido probada, o de la estructura interna de la mente. 5 y 6 son dudables ya que también carecen de justificación, basándose en los prejuicios del criticante, siendo ``al estar programadas para el test, deberían ser capaces de simular X'' siempre que X sea una habilidad evaluable en conversaciones, una contra-crítica equivalente que es la que Turing parece esgrimir.

Segunda categoría, ``Objeciones matemáticas''. Al ser la base de la máquina inteligente propuesta por Turing un constructo capaz únicamente de realizar matemática sobre conjuntos discretos (Turing-completitud, recordemos), surgen las siguientes objecciones: 

\begin{enumerate}
    \item[\textbf{3}] La máquina no puede tratar problemas indecidibles de la lógica al estar basada en ella (i.e.\ preguntada por el problema de la parada la máquina daría una respuesta errónea o entraría en un bucle infinito).
    \item[\textbf{7}] La máquina es un artefacto limitado a dominios discretos mientras que el cerebro humano opera sobre dominios continuos.
\end{enumerate}

Turing considera que no existe demostración de que las limitaciones de 3 no ocurran también en la mente humana y, que si una máquina da una respuesta errónea a estos problemas no es relevante puesto que hay humanos que también la darían. Ésta crítica a 3 se usa también como base para hablar de la \textit{superarticularidad}, consistente en el aumento de capacidades intelectuales humanas como resultado de la competencia con máquinas más inteligentes que éstos:
\begin{quotation}
``There would be no question of triumphing simultaneously over all machines. In short, then, there might be men cleverer than any given machine, but then again there might be other machines cleverer again, and so on.'' \parencite[apartado 6, punto 3]{Turing1950cmi}
\end{quotation}

Como respuesta a 7 Turing afirma que un ajuste discreto a una función continua, digamos, calcular el valor exacto de $\pi$, podrían darse resultados suficientemente similares a los que \textbf{un humano daría} para las preguntas formuladas en el juego (i.e. números de precisión finita suficientemente cercanos al valor de $\pi$ como $3.1415$), y, en todo caso, como ya hemos visto las neuronas operan fundamentalmente en términos discretos.

Tercera categoría, la objeción número \textbf{8}: ``El comportamiento humano es arbitrario''. Ésta objeción consiste en que no existe un algoritmo o una tabla de reglas para calcular o predecir el comportamiento de un sujeto humano en todos las situaciones posibles. El contraargumento de Turing afirma que no es sensato afirmar que los humanos no ``funcionan'' bajo tales reglas (en cuyo caso serían ciertamente una máquina, fuere o no Turing-completa) ya que no se ha demostrado, mediante la ciencia, que no existan. Como extensión afirma que si tuviésemos un programa que responde a un número de dieciséis cifras con otro de forma arbitraria un observador podría similarmente concluir que es completamente arbitrario y carece de leyes de comportamiento, aunque sabemos que alguien ha escrito un código para este funcionamiento.

En la parte final del artículo se describe el proceso de \textit{aprendizaje máquina}, que ha devenido en un campo propio en la inteligencia artificial. Turing denomina \textit{mentes supercríticas}, por analogía con los materiales atómicos, aquellas en las que la inyección de material nuevo, ideas y experiencias, provoca una reacción que conduce a ideas nuevas de forma continuada\footnote{Por la misma analogía, Turing describe las mentes animales como \textit{mentes subcríticas}, que responderían a cada nuevo estímulo o experiencia sin generar ideas nuevas, e incapaces de generación de ideas a partir de ideas.}. Turing presupone que un método aleatoreizado puede ser mejor para la generación de este tipo de aprendizaje, ya que no cree ver reglas en el mismo. El aprendizaje máquina  plantea como hipótesis que la mente del niño es aún así sustancialmente más simple que la del adulto, siendo la mente del adulto la mente del niño añadiendo experiencias de aprendizaje y generando ideas de forma supercrítica. Por tanto, suponemos que el modelado de la mente infantil sería más simple y podríamos diseñar el programa de forma que aprendiese presentándole experiencias, de tal forma que en cuanto el proceso generase un estado del programa ``adulto'' pudiese pasar el Test de Turing. Creemos que es relevante como relación de un método de generación de inteligencia, pero el núcleo del artículo es la descripción del test y sus objeciones.


\section{Limitaciones del Test de Turing}

Ahora que hemos comentado el artículo de Turing estamos en posición de enumerar  críticas al experimento y contraargumentarlas o aceptarlas. Existen críticas metodológicas y críticas a los fundamentos epistemológicos y psicológicos principalmente.

\nocite{katrina}
\nocite{afterTuring}
\nocite{turingHarmful}
\nocite{harnad}
\nocite{sep-turing-test}

\subsection{Críticas al método}

Al tratarse de una sustitución de habilidades inteligentes por aquellas habilidades que pueden reflejarse únicamente mediante el lenguaje escrito, siendo los comportamientos inteligentes humanos más diversos, se puede deducir que el conjunto de capacidades de acto inteligente que pueden detectarse es menor que el conjunto total de actos inteligentes que es capaz de desarrollar un humano. Gunderson, citado en \parencite[apartado 3.1]{afterTuring}, usa un experimento mental análogo al Test de Turing, el \textit{juego del pisar pies}, para demostrar que su potencial de detección de inteligencia es de hecho menor: Imaginemos que tratamos de adivinar si el sujeto en una habitación es una mujer o un hombre, para lo que disponemos de una rendija por la que meter el pie. Se supone que si recibimos un pisotón, es que hay un humano dentro y podríamos distinguir si es mujer u hombre por las ``cualidades'' del pisotón, pero si se construye un sistema que deje caer una piedra cada vez que alguien introduzca el pie por el agujero, dice Gunderson, podríamos identificar la piedra como humano. De acuerdo a Gunderson, aunque los sistemas automáticos que dan pisotones con piedras fuesen capaces de pasar este test, no constituiría prueba de humanidad en ningún caso. Esta crítica es una ejemplificación de un falso positivo que se sostiene en que la capacidad de reconocer humanidad a partir de poder pisar un pie es limitada. 

Un falso positivo es un resultado positivo en un test binario, de resultados posibles positivo o negativo, que debería ser negativo. Por ejemplo, en el Test de Turing la identificación de una máquina que no posee inteligencia general humana como humana. En el caso del Test de Turing surgen principalmente del hecho de que se trata de una prueba indirecta, que trata de probar algo que no se puede probar directamente (``ser inteligente'') mediante un método auxiliar (``ser capaz de ser identificado como humano''). Creemos que la crítica de Gunderson es sensata en general, ya que el experimento de Turing tiene posiblemente falsos positivos, pero obvia que las capacidades derivadas del lenguaje tienen una relación más profunda con la inteligencia que pisar un pie con la cualidad de ser humano, a saber, con habilidades lingüísticas puede explicarse a otro ser que comprenda el lenguaje cómo realizar casi cualquier tarea. En todo caso, para que el Test de Turing fuese un experimento fiable deberíamos poder asegurar que esté libre de falsos positivos y falsos negativos, o al menos poder limitarlos.

Para lidiar con el problema de los falsos positivos y negativos existen reformulaciones posteriores del Test de Turing que los admiten, integrándolos en el proceso de prueba\footnote{En \parencite[apartado 6.1]{afterTuring} se llega a afirmar que el Test \textit{nunca} se ha aplicado tal y como describe Turing, con 3 participantes y una sola vez.}. Un ejemplo es el usado en el premio Loebner \parencite[apartado 6.1]{afterTuring} cuya primera edición consistió en un Test con identificación humano o no-humano votada por 10 interrogadores. Otra manera de lidiar con la posibilidad de error es añadir más pruebas continuadas, estableciendo una especie de definición inductiva de inteligencia cuyo valor vaya corrigiéndose a medida que las pruebas se van sucediendo. Moor \parencite[apartado 3.4]{afterTuring} entiende que éste es el caso y propone un test continuado que se usa como \textit{toma de datos} progresiva para tomar una decisión. Moor acepta que el Test es funcionalmente adecuado para la evaluación de todos los aspectos de la inteligencia, siendo además extremadamente complejo de pasar dado que tener una sola habilidad cognitiva compleja aprendida no es suficiente, hay que tener una serie de habilidades complejas. Sin embargo, Moor comenta que si la máquina tuviese condiciones de operación interna que obligasen a revisar la decisión tomada, sería necesario hacerlo, pero no identifica qué condiciones se requieren, por lo que consideramos ésta parte del comentario vacía de contenido. También, Block \parencite[apartado 4.1]{afterTuring} considera que esta falibilidad de los humanos como un problema intrínseco al Test, pero parece argüir que un número suficientemente grande de jueces sería capaz de alcanzar un consenso sobre la inteligencia de una entidad determinada. Como sistemas más rigurosos se propone que las máquinas sean capaces de realizar, en lugar de un Test normal, un examen general con preguntas estandardizadas y mensurables sobre sentido común y conocimiento del mundo \parencite{standardTesting}.

Como comentario a los test múltiples que hemos presentado, entendemos que varios jueces humanos, de ser capaces de detectar correctamente la inteligencia más de un 50\% de las veces tendrían más exito de media que un juez humano en solitario, sin embargo, si su capacidad para detectar inteligencia fuese menor que un 50\% de decisiones correctas sus errores se multiplicarían. Por lo tanto, deberíamos ser capaces de establecer algún tipo de métrica de errores para poder enmendarlos. En este caso retomamos la idea que avanzábamos en el análisis del Test, de usar la identificación correcta o incorrecta en el test sin máquinas como un \textit{grupo de control}, para tomarlo como referencia del juicio de cada uno de los interrogadores y poder corregirlos.

\subsection{Críticas a los fundamentos epistemológicos}

Teniendo en cuenta que el Test de Turing trata sobre la detección de \textit{otra mente}, siendo las otras mentes no observables directamente, lo cual es un problema epistemológico: tengo razones suficientes para creer que yo mismo tengo mente (o consciencia, o inteligencia), pero \textit{¿cómo podría tenerla de otros seres humanos?}. Turing argumenta que no debería ser un problema \parencite[apartado 6, punto 4]{Turing1950cmi}, ya que considerar seriamente que no existe la mente de una entidad desconocida que podría ser un humano o una máquina es caer en el solipsismo. La razón por la que habíamos propuesto sustituir ``inteligencia'' por ``comportamientos inteligentes'' es precisamente lidiar con el hecho de que no podemos afirmar que existan entidades no observables y separar dicho problema en dos problemas más fáciles de resolver: la máquina puede realizar comportamientos inteligentes y la máquina posee inteligencia. El primero es entonces razón necesaria, aunque no suficiente, para dar soporte al segundo, por lo tanto tenemos un problema que podemos resolver aunque sus fundamentos no sean completamente correctos.

Más allá de la limitación del Test respecto a sus falsos positivos y negativos cabe preguntarse cómo han de ser los actos inteligentes que se identifiquen y qué clase de inteligencia evidencian, humana o no. Las críticas de Robert French van encaminadas en este sentido. En 1990 \parencite[apartado 4.5]{afterTuring} French postula un test para la capacidad de volar en una isla del mar del Norte cuyos únicos ejemplos de objetos voladores son gaviotas. El paralelismo se traza en el momento en que una máquina capaz de volar cruza su modelo de ``objeto volador'', que está basado en las gaviotas y asume que la capacidad de volar de éstas debería ser indescernible de cualquier entidad voladora. La conclusión de este experimento mental es la existencia de comportamientos inteligentes \textit{no humanos} que pasen desapercibidos al test. Otras críticas, también de French, involucran habilidades singularmente humanas como necesarias para la inteligencia, como el ser capaces de identificar hojas secas como un escondrijo útil o la evaluación de nombres de cereales como atractivos o no. De nuevo nos topamos con el problema de la definición de inteligencia, que en general toma la inteligencia asumida en humanos como base. Podemos criticar el experimento de French afirmando que la manera en la que los humanos piensan\footnote{El propio French afirma la existencia de ``procesos subcognitivos'' que serían detectables mediante ``preguntas subcognitivas''. French afirma que un Test de Turing aplicado con suficiente rigor contendría dichas preguntas implícita o explícitamente.}, dividiendo y abstrayendo la realidad en objetos y conceptos simples, es comparativamente eficiente y tal vez por eso sea una muestra de \textit{inteligencia general} y probablemente el único modelo de inteligencia viable en un entorno evolutivo competitivo \parencite{aliens}. Por tanto, afirma Minsky, al ser la cognición de tipo humano la más probable biológicamente nos permitiría incluso comunicarnos con vida desarrollada fuera de la tierra (`aliens`) bajo los principios de la selección natural. En cualquier caso, la crítica de French sobre que el test sólo permite detectar inteligencia humana se mantiene.  Millar esgrime una crítica similar \parencite[apartado 3.3]{afterTuring} diciendo que la inteligencia en máquinas debe \textit{antropormofizarse} para poder pasar el Test. En general éstas críticas se deben al hecho de ser un test centrado en humanos, cuyos jueces son humanos que naturalmente tienen prejuicios sobre cómo debería ser otro humano incluyendo cuestiones culturales, pero para ser válidas habría que demostrar que existe cognición no humana\footnote{En el apéndice \ref{cognitiveHistory} indicamos que existen indicios que podrían indicar la existencia de inteligencias no humanas en plantas y animales.} o que un Test de Turing aplicado a gente de cultura diferente daría falsos negativos\footnote{Es posible incluso que la habilidad de la máquina para simular la cultura de su adversario haga que la identificación sea más o menos precisa. La influencia social sobre la máquina inteligente es ciertamente un punto interesante a explorar, ya que suele asumirse que la máquina existe sólamente para el Test de Turing, y probablemente para una identificación de inteligencia serían relevantes experiencias externas. Existe material desarrollado en las ciencias sociales sobre el Test, listado en \parencite[apartado 5]{afterTuring}.}. 

Otras limitaciones implican que una mente mecánica podría no tener ciertas cualidades humanas. Turing ya había respondido a críticas de éste tipo en su artículo, pero las relatamos aquí como recopilación. Donald Michie \parencite[apartado 4.3]{afterTuring} afirma que el Test no captura el pensamiento subconsciente y que las máquinas son incapaces de generar este tipo de pensamiento dando como ejemplo que cualquier ser humano que hablase inglés debería saber cuál es el plural de una serie de palabras, aunque fuesen inventadas, en inglés. La crítica consiste en que es imposible que un programador considere todas las reglas del lenguaje, como las de pluralización, y las programe en una máquina. En realidad, si la máquina es capaz de generar frases arbitrarias, al contrario que tener frases pre-generadas, entendemos que sería capaz de extraer dichas reglas del lenguaje y además, no evidencia la existencia de pensamiento subconsciente en el proceso lingüístico, sino que se trata de una regla lingüística aprendida y generalizada en la mayor parte de los humanos que conocen el idioma inglés.

En relación a esta crítica está la habitación china de Searle, \parencite{searleChineseRoom} y \parencite[apartado 4.2]{afterTuring}, que postula una habitación que recibe mensajes escritos en chino teniendo al propio Searle dentro (que no entiende el chino) equipado con un manual que le dice qué simbolos escoger para elaborar sus respuestas a los mensajes entrantes. Searle critica que dicha habitación podría ser capaz, en teoría, de superar el Test. Sin embargo, ninguna de las partes componentes entiende el lenguaje y además carecen de \textit{intencionalidad}, que para Searle es una parte esencial de la cognición humana. Por lo tanto, según Searle, podríamos detectar inteligencia con el Test pero nunca intencionalidad real. Esto está directamente relacionado con los comentarios de lady Lovelace, ``The Analytical Engine (el computador Turing-completo creado por Babbage) has no pretensions to originate anything. It can do whatever we know how to order it to perform'' \parencite[apartado 2.6]{sep-turing-test}, que Turing ya responde en su artículo. En caso que aceptásemos esta crítica habría un test alternativo, propuesto por Bringsjord \parencite[apartado 5.3.2]{sep-turing-test}, que consiste en que el test debe \textit{meta-analizarse} para determinar si la máquina tiene de hecho intencionalidad más allá de lo programado: el método que proponen consiste en preguntar al creador de la máquina o a alguien equivalente cómo ha producido una respuesta determinada y si el autor no puede explicarlo con referencias a las funciones básicas de la máquina, hay intencionalidad. Creemos en todo caso que el concepto de intencionalidad no está claro en ningún caso, ni siquiera para seres admitidos por consenso como vivos como los humanos.

Podemos arguír que el único libro que puede hacer que Searle sea capaz de elaborar respuestas con sentido para que pueda pasar el Test es un manual que enseñe chino a Searle o un manual que traduzca entre frases del chino y el inglés perfectamente o una transformación entre frases en chino y un modelo de datos de la situación que se va desarrollando durante la conversación\footnote{Por ejemplo, si el mensaje incluye ``Yo soy filósofo'' en chino, la máquina debería recordar que el adversario es filósofo y generar o recordar hechos relativos a cualidades de los filósofos que sean relevantes. Las conversaciones en éste sentido son altamente contextuales.}, ya que cualquier conversación en chino o en cualquier otro idioma no posee una estructura tan simple como una tabla pregunta-respuesta, como Searle parece entender\footnote{Críticas similares incluyen el ``saber todas las conversaciones de longitud x previamente'' de Ned Block \parencite[apartado 4.1]{afterTuring} que afirma que una máquina podría simplemente extraer respuestas pre-generadas desde una lista. Esto obvia que construir dicha lista es materialmente imposible al ser todas las conversaciones infinitas no numerables, dependientes del contexto y de sí mismas. Otras críticas de Block se centran en criticar el conductualismo del Test, argumentando la existencia de características intrínsecas a la inteligencia que un test conductual no captura.}. Evaluar el lenguaje no es trivial en todo caso, y en una conversación se establecen hechos, y relaciones entre palabras y relaciones entre palabras y hechos que una máquina que pase el Test debe ser capaz de identificar y desarrollar para que la comunicación sea una imitación humana fidedigna. 

Por tanto, o bien las instrucciones de la habitación china incorporan un mecanismo de comprensión de palabras en chino asociadas a la respuesta y un modelo del contexto relacionado a las palabras en chino, o bien Searle, concretamente, ha llegado a entender el chino en la habitación. El problema que plantea la habitación china de Searle tiene el suficiente alcance para poder desarrollar varios artículos por sí mismo y forma parte del movimiento anti-conductualista de la disciplina psicológica en la década de los 80 y 90.

Entendemos que para que un comportamiento pueda considerarse inteligente debe existir posibilidad de error, entendido como una desviación entre la intencionalidad anterior al acto y  el estado del mundo después del mismo, en el sentido de que el agente sea capaz de probar soluciones que no garantizan un resultado correcto y el agente que realiza dicho comportamiento debe ser capaz de detectar esta divergencia en algún momento y corregirla, aumentando sus propias capacidades con el tiempo. Para ello el agente debe ser capaz de continuarse autónomamente durante el tiempo suficiente mientras se enfrenta a nuevos retos o crear sucesores de sí mismo que perpetúen comportamientos máquina similares. En el segundo caso la inteligencia se daría por selección natural, dado que el entorno condicionaría la supervivencia únicamente de los individuos adecuadamente inteligentes. Consideramos, al igual que French, que el Test de Turing es suficientemente impredecible como para dar a la máquina un reto suficiente en el que comprobar que puede generar soluciones originales a problemas cognitivos, nominalmente la situación en la que una máquina debe poseer una apariencia y un carácter humanos que describir y sobre los que ser consistente narrativamente.

En este sentido social y evolutivo, Schweizer, \parencite[apartado 4.4.4]{afterTuring} y \parencite[apartado 5.3.3]{sep-turing-test} arguye que el test no debería ser aplicado a individuos sino a máquinas capaces de reproducirse y tener descendencias en su misma ``especie'', y denomina a su versión \textit{TRue Total Turing Test}. El TRTTT es un sucesor del \textit{Test de Turing Total}, \parencite[apartado 4.4.1]{afterTuring} y \parencite[apartado 5.3.1]{sep-turing-test}, propuesto por Harnad en el que propone que las máquinas deberían ser capaces de realizar actos físicos para ser consideradas inteligentes, lo que se conoce como \textit{mente-en-cuerpo} (\textit{embodied mind}, en el inglés original, la traducción es mía) la idea de que ciertas categorías mentales y lingüísticas están derivadas de la información proveniente de los sentidos y la consciencia del propio cuerpo \parencite{lakoffEmbodiedCognition} y que, por tanto, la capacidad lingüística depende en gran medida de la habilidad motora. Resulta difícil de creer que una máquina que no modelase correctamente este tipo de metáforas e ideas extraídas del conocimiento pudiese pasar el test de Turing, aunque en principio no parezca existir ningún inconveniente en que sean simplemente simulados sus órganos, por tanto resulta evidente que una máquina que no pudiese pasar el Test original pudiese pasar algunas de sus extensiones, por tanto hasta que se dé el caso de que una máquina pasa consistentemente el Test de Turing no debería trabajarse hacia ninguna de sus extensiones: resumiendo, bajo la hipótesis de que es posible imitar el cuerpo y la evolución de un ser vivo mediante máquinas, podemos trabajar para pasar el Test original aunque la tesis de la mente-en-cuerpo sea cierta.

\nocite{newmind}

Volviendo al tema de la atribución de inteligencia es interesante considerar qué ocurriría si sustituímos al evaluador del Test por una máquina. La máquina, de poseer inteligencia equivalente a la humana, debería ser capaz de identificar correcta e incorrectamente máquinas y humanos con una tasa de errores como mínimo similar a la de un humano. Si la máquina tuviese menos errores podríamos concluir únicamente que tiene una inteligencia especializada en este problema, a menos que muestre que esta especialización surge de habilidades mayores que las humanas. Podemos considerar si para la identificación correcta y la imitación de un humano correcta (ambos roles del Test) debe ser necesaria la existencia de una teoría de la mente en dicha máquina, es decir, la capacidad de atribuír estados mentales a entidades que interaccionen con la misma. La respuesta a esta pregunta determinaría si la atribución de estados mentales y la identificación de actos inteligentes es un comportamiento inteligente en sí mismo que el Test original no captura. Este test fue propuesto, históricamente por Watt en 1996 \parencite[apartado 4.4.3]{afterTuring}, afirmando que es la consecuencia lógica en la comunidad psicológica de la necesidad de una definición operativa de inteligencia ante la imposibilidad de afirmar que esta existe, lo que es equivalente al problema de las \textit{otras mentes} que mencionamos antes.

Todas estas críticas convergen, en el contexto de Inteligencia Artificial, en el si existe distinción ontológica entre la inteligencia creada artificialmente y la inteligencia natural. Es decir, si logramos crear inteligencia, sea ésta lo que sea, ¿existe aún alguna diferencia entre lo que hemos construido y la inteligencia humana? Si aceptamos esta crítica entramos en una distinción similar a la que propone Searle: entre una cierta \textit{IA débil} en la que la IA no es una mente humana real ya que carece de aspectos de ésta, como la intencionalidad o la consciencia, y una \textit{IA fuerte} entendida como la IA \textit{siendo} una mente real en todos sus aspectos. Varios argumentos que hemos presentado; vide Searle, Schweizer, Harnad y las ideas de \textit{mente-en-cuerpo}; parecen implicar que es necesario un entorno del que aprender y unos órganos que provean necesidades para satisfacer e información de su propio estado, para que el sistema cognitivo de la máquina tenga información para desarrollarse y generar nuevas ideas. Sin embargo, no hay impedimento teórico por el momento para que una máquina pueda simular todos estos sistemas. 

\chapter{Conclusiones}

En este trabajo hemos expuesto perspectivas históricas referentes a la creación de máquinas inteligentes en los campos de la maquinaria computacional y la algoritmia como referentes a la base de la inteligencia y la definición de inteligencia en la parte filosófica del problema. Hemos enmarcado el Test de Turing en sus orígenes filosóficos, psicológicos y tecnológicos. Hemos ligado el problema de la IA con el problema de los indescernibles y la filosofía de la tecnología.

Partiendo de las limitaciones detectadas en el Test se ha remarcado la diferencia entre la definición de inteligencia y los comportamientos inteligentes, permitiendo evadir el platonismo de asumir que inteligencia es una entidad, por lo que se caracteriza el Test de Turing como una forma productiva de comprobar si una entidad realiza, de facto, comportamientos inteligentes, aunque tenga limitaciones claras precisamente por su propia formulación funcionalista. En ningún caso el Test avanza hacia una definición más precisa de inteligencia, siendo necesaria una meta-evaluación del mismo para llegar a ella, caso que anticipamos al hablar de las objeciones de lady Lovelace. Es decir, se considera que para entender mejor cómo opera la inteligencia, de existir, debe hacerse un análisis riguroso de los comportamientos que identifican como inteligente y también de los que identifican como no-inteligente. De cómo podría decorrer dicho análisis se deja para un estudio más pormenorizado de los avances psicológicos y filosóficos en la definición de inteligencia.

Se han identificado también limitaciones operativas en la aplicación de dicho Test. El Test asume que el juicio de un humano arbitrario es capaz de detectar inteligencia de una forma fiable, sin existir diferencias en tal juicio entre los casos en los que el sujeto de la prueba es un humano o una máquina. Hace posible identificar máquinas carentes de inteligencia general como tales (falsos positivos). También hace posible que máquinas capaces de actos inteligentes pero sin la habilidad de fingir ser humano, como posibles inteligencias alienígenas, animales etc., no sean considerados como inteligentes (falsos negativos).

Vemos que el Test de Turing aún así nos da una definición operativa, aunque ya no sea usada en los grupos que crean maquinaria inteligente orientada a tareas\footnote{La definición operativa suele basarse en métricas de \textit{precision} y \textit{recall} sobre conjuntos de datos estándar, para comprobar mejoras y diferencias en ajuste de funciones y clasificación.}, es necesaria por el momento para la identificación de inteligencia general. Uno de los objetivos de la Inteligencia Artificial como disciplina debería ser la identificación y caracterización de los comportamientos inteligentes y el desarrollo de pruebas científicas de la misma. La necesidad de colaboración con la psicología, la neurociencia y el resto de las ciencias cognitivas se hace aquí evidente.


% Last pages for ToC
%-------------------------------------------------------------------------------
\newpage

\begin{appendices}

\chapter{Historia del Hardware Computacional}
\label{compHis}

Se incluye aquí un resumen y comentario sobre la historia de la maquinaria de computación, cuyos puntos clave han sido extraídos de \parencite{wiki:computerhistory}.

Históricamente el computador de propósito general fue diseñado por Charles Babbage en 1833, aunque no fue construído hasta el siglo XX por, primero, su hijo Prevost que construyó una parte mínima esencial del mismo que era capaz de ejecutar programas simples en 1910, y en última instancia fue imitado por el Museo de Ciencias de Londres con materiales de la época sin éxito a finales del siglo XX. Aún así se considera que el prototipo, de llegar a cumplir sus especificaciones de diseño, sería Turing-completo, sólo limitado por la precisión numérica y la memoria total de manera similar a la que cualquier computador actual lo sería. En la primera mitad del siglo XX encontramos gran cantidad de máquinas de cómputo, incluso cajeros automáticos de cobro mecánicos y electrónicos con sistemas de ayuda al cálculo de balances, pero ninguna cumple la propiedad de ser lo suficientemente general para ejecutar algoritmos recursivos.

Será en 1944 cuando se cree el Colossus Mark II, el primer computador electrónico digital Turing-completo que se mantuvo en secreto hasta la década de 1970 ya que fue planeado también para romper códigos, y usado durante la guerra fría. Éste constructo es otro ejemplo de la confluencia de ideas que se fue gestando desde el siglo XIX con la publicación de George Boole\footnote{Otros ejemplos de ésta confluencia son los trabajos en lógica de Russell y Whitehead, el proyecto formalista de Hilbert o los teoremas de Gödel.} \textit{Las leyes del pensamiento}, que inaugura el cálculo lógico binario (o booleano), y desarrollado por Alfred Whitehead. Claude Shannon, fundador de la teoría de la información como entropía e ingeniero eléctrico, demuestra que las operaciones de la lógica booleana pueden construírse mediante la adaptación a circuítos eléctricos entendiendo el símbolo básico $0$ como la ausencia de corriente eléctrica y el símbolo $1$ como la presencia de la misma. La idea de usar la lógica simbólica como base de todas las matemáticas, y la idea de \textit{Gödelización} como transformación de enunciados en números y su posterior procesado, confluyen también en la generación de la idea de la Máquina de Turing Universal ya presente en \textit{On Computable Numbers} y consistente en la aplicación de una máquina de Turing que puede aceptar como entrada otras máquinas de Turing transformadas en números naturales y ejecutarlas. Se puede demostrar también que una máquina de Turing, para ser Turing-completa, únicamente precisa del uso de dos símbolos, $0$ y $1$. 

Cabe notar que éste computador era programable en el sentido de que permitía la interconexión arbitraria de elementos que no es que tuviesen programas almacenados sino que eran módulos de cálculo especializados en una tarea concreta referida al cálculo booleano o de aplicación criptográfica, no porque permitiese especificar un programa a nivel de memoria como se hace actualmente, siendo gran parte de estas tareas gestionadas por el sistema operativo. Para la carga en memoria de programas se tendría que esperar a la arquitectura von Neumann y al desarrollo de los chips y memorias magnéticas.

En la década de los 50 todas estas ideas se amplían y se comercializan. La invención de la microprogramación, hoy conocida como \textit{firmware} que permite la adición de nuevas instrucciones programadas sobre una máquina física, sin cambiar la máquina, simplifica el desarrollo de las máquinas de cómputo haciéndolas más flexibles. En 1955 los computadores sustituyen los circuítos basados en tubos de vacío por circuítos basados en transistores, reduciendo su tamaño en órdenes de magnitud y aumentando su velocidad en igual medida. Ésto se suele nombrar en la literatura como ``segunda generación''.

En la década de los 60 se produce el gran salto de la computación al consumo generalizado, no por parte de la inmensa mayoría de la población sino por instituciones y grandes empresas, lanzándose el primer computador que podríamos llamar ``popular'', el IBM 1401. Consistía en un computador configurable que se podía alquilar por unos veinte mil euros mensuales, al cambio actual, lo que permitió a un gran número de entidades entrar en el uso de las computadoras. Lo que hoy conocemos como mainframe requería que un ingeniero configurase el computador y cargase los programas ya escritos en el mismo y preparados para el lenguaje de la máquina que los ejecutaría, decidiendo cuánto tiempo debería gastar cada uno y en qué orden: la automatización de estas tareas dará lugar en las próximas décadas a los sistemas operativos, el uso de mainframes en tiempo compartido y en última instancia a los sistemas distribuídos y paralelos. 

Tambien de esta época son los primeros lenguajes de programación por encima del nivel de lenguaje máquina, LISP y Fortran, que requerían una etapa de traducción intermedia y aún se usan hoy en día. LISP es uno de los lenguajes clave en el desarrollo de la IA en las últimas décadas, ya que, basado en el cálculo lambda de Church, es un lenguaje que permite expresar programas de procesado de listas mediante listas de instrucciones donde datos y programa están expresados en el mismo lenguaje. Los primeros sistemas operativos, como OS/360 cuya historia de desarrollo está narrada en \textit{The mythical Man-Month}, también son de ésta época. En la era del mainframe cada una de las máquinas solía ser enviada al cliente con un sistema operativo adaptado a sus necesidades específicas, los sistemas operativos de consumo general, configurables por sí mismos, no aparecerán hasta la generalización de componentes de consumo que permitan que el sistema operativo pueda ser manufacturado por separado de la máquina, e integrado en varias máquinas.

Los sistemas de tercera generación (en esencia circuítos integrados conectados mediante cables) y de cuarta generación (circuítos integrados conectados mediante circuítos integrados) serán desarrollados a mediados de la década de los 60 y de la década de los 70 respectivamente. Dado que las diferencias entre ambas generaciones sólo aparecen durante el proceso de manufactura de los mismos hemos decidido obviarlas y centrarnos en los efectos que produce sobre el comercio de computadores: mayor velocidad en menor tamaño y menor precio. Para finales de la década de los 70 el computador personal ya era un hecho y los Apple II, Commodore e IBM-PC podían verse en hogares de todo el mundo, incluída España, donde se considera que hubo una \textit{edad de oro} del software durante los años 80.

Entre los años 80 y nuestra era los computadores han ido incrementando su capacidad computacional en velocidad y capacidad de memoria de acuerdo con la Ley de Moore, que postula que el avance de tecnología permite introducir el doble de transistores en una placa del mismo tamaño más o menos cada dos años. Ésta ley se ha topado recientemente con la limitación práctica de que el calor disipado y energía consumida por un computador altamente integrado también aumentan, precisando que dicho computador posea refrigeración y alimentación eléctrica no razonables. También, teóricamente, se postula un límite duro para dicha ley en el momento que los transistores no puedan funcionar debido a su relación de tamaño con la escala de los fenómenos cuánticos. Por estas razones hoy se tiende a aumentar la eficiencia de los sistemas no aumentando la cantidad de operaciones en serie, sino que se aumenta la cantidad de operaciones que pueden hacerse simultáneamente mediante paralelización o distribución de tareas.

\chapter{El giro cognitivista}
\label{cognitiveHistory}

Veremos a continuación un pequeño resumen\footnote{Una versión extendida del comentario realizado por el autor en la asignatura Fª de la Mente al nacimiento de las ciencias cognitivas.} de la segunda mitad del siglo XX que explica la convergencia de diversos grupos científicos de lingüistas, psicólogos, neurocientíficos, economistas, filósofos y computólogos en lo que hoy se conoce como \textit{ciencias cognitivas}.

Definimos \textit{ciencia cognitiva} como toda ciencia que se ocupa de uno o más aspectos de los fenómenos de la cognición. Como tales, las ciencias cognitivas forman un conjunto de ciencias y al mismo tiempo un campo de investigación interdisciplinar cuyo tema central es el estudio de la cognición humana, animal y mecánica \parencite[p.20]{pmf07}, que es a la vez la fuente, se cree, de los comportamientos inteligentes. Se distinguen dos conceptos de cognición: cognición A, aquella que se refiere a la acción de tomar en cuenta una realidad o, dicho de un modo más apropiado a la terminología científica, como recepción de información y cognición B, como el uso y manejo de dicha información. Tanto en el primer y segundo caso se hacen asunciones sobre la capacidad del ser humano de recibir o hacer uso de cualquier información, así como la existencia en cierto grado de dicha información. Existen múltiples concepciones de la información que sirven de base a conocimientos tan diversos como la medición cuantitativa del contenido de un texto fuente (p.e. la concepción informativa de Shannon como desorden, que ya hemos visto en el capítulo anterior) o la fundación de la capacidad deductiva de la lógica clásica (p.e. la concepción objetivista informativa de Corcoran).

Tal y como lo expresan Allen Newell y Herbert Simon en \textit{Human Problem Solving}
(1972) el ser humano y su capacidad intelectual, y al mismo tiempo las máquinas formales de cómputo (i.e. las máquinas Turing-equivalentes) pertenecen al género, por analogía biológica, `sistema de procesamiento de información'. La constitución de las ciencias cognitivas como grupo de interés en las funciones cognitivas de animales, humanos y máquinas, comienza en la llamada ``conferencia Dartmouth'', una conferencia de matemáticos y lógicos que pone de manifiesto el auge de una disciplina informática llamada inteligencia artificial, cuyo objetivo es la obtención de comportamiento que denominaríamos inteligente en sistemas artificiales: a saber, máquinas sentientes, capaces de actuación o razonamiento autónomo. Más allá de la cognición en animales y máquinas, se comienza a sospechar que los reinos de las plantas, los hongos e incluso los virus tienen algún tipo de cognición. Por ejemplo, se ha demostrado que las plantas segregan neurotransmisores que usan para regular su crecimiento cuando se identifica una situación de estrés como un aumento en la acidez del suelo o carencia de agua \parencite{plants}, y que las agresiones les proporcionan información sobre su entorno que usan para crecer de forma más efectiva o la necesidad de contar hasta 5 para segregar ciertas substancias \parencite{plantCognition}.

Otro de los momentos importantes para este grupo de interés es el nacimiento de la psicología cognitiva, manifestado en tres hechos: la fundación en 1960 del Harvard Center for Cognitive Studies, la publicación en ese mismo año de \textit{Plans and the Structure of Behaviour} de George A. Miller y la publicación en 1967 del primer libro de texto de esta escuela de pensamiento psicológico. Con la psicología cognitiva se recupera el mentalismo, esto es, la existencia de una vida mental interna que es al menos parcialmente ajena a la materia y se deja de lado el conductismo, y por tanto el funcionalismo, como mencionamos antes. Además, el postulado de los procesos mentales que es inherente a la psicología cognitiva, asume un cierto compromiso con el computacionalismo, la existencia de procesos que podrían ser simulados o reproducidos mediante máquinas, y acerca esta escuela a los propósitos de la inteligencia artificial.


 Tal y como se dice en \parencite{ciberneticsAshby}: ``La cibernética es a la máquina real (electrónica, mecánica, neural o económica) lo que la geometría es a los objetos materiales de nuestro espacio terrestre'', en el sentido de que es una descripción simplificada, y certifica más adelante con ``La cibernética es entonces indiferente al reproche de que algunas de las máquinas que estudia no están incluídas en las que encontramos entre nosotros''. La palabra \textit{Cibernética} se refiere aquí una disciplina generalista creada en la década de 1940 y que dio origen, entre otras cosas, a lo que hoy referimos como Inteligencia Artificial en la ``Conferencia Dartmouth'' de 1956, instituyéndose como una de las ciencias cognitivas como veremos. Cibernética, que proviene del griego \textit{Kyvernêtès} referido al timonel que \textit{gobierna} un barco, comprendía una descripción general de todos los sistemas complejos, incluídas la vida, las máquinas, la mente humana, la economía\textit{Que Ashby, tal y como hemos citado, entendía la economía como si fuese una máquina procesadora de bienes y capital.} y varias disciplinas matemáticas aplicadas intentando encontrar un lenguaje que permitiese expresar las interacciones en todos ellos, es decir ``la ciencia del control'' de todos éstos sistemas. Hoy en día ``cibernética'' se usa en lengauje académico como término para agrupar diferentes campos de éstas ciencias además de en la política, la sociología y los estudios organizativos y de empresa. Parafraseando a \parencite{pylyshyn70} en su comentario sobre algoritmia, la cibernética es más una cosmovisión que un campo de la ciencia aislado.

El campo de trabajo de Ashby era, en términos generales, la aplicación de los principios de la ciencia de la computación a la biología y especialmente a la neurociencia. Dejando a un lado que Ashby asume que el comportamiento inteligente es claramente mecánico, entendemos que la Inteligencia Artificial no escapa a la creación de comportamientos inteligentes fuera del ámbito humano pues, en primer lugar, tal vez no interesa la reproducción exacta y completa de todos los comportamientos a los que atribuiríamos inteligencia. Se entiende todo sistema complejo, desde la maquinaria formada por múltiples máquinas simples hasta las redes sociales pasando por los sistemas neuronales como una máquina compleja cuyas leyes son: finitas y cogentes; en el sentido de que unas no contradicen a otras en el mismo sistema, es decir, que el universo descrito no entra en contradicción interna; imitables por otros sistemas de la misma complejidad y sólo dependientes de lo observable externamente.
 
Es decir, en el caso de Ashby aún no se había dado el giro cognitivista respecto a los fenómenos mentales, y Ashby trata la mente como un constructo mecánico cuyas piezas son irrelevantes y de las cuales el funcionamiento observable es lo único relevante. Un funcionalismo que será, 50 años más tarde, destituído en las ciencias cognitivas por dos elementos: en la inteligencia artificial por las técnicas aplicadas a problemas reales, ya que la investigación en la explicación de la mente y el conocimiento será otorgada a los psicólogos, y en la psicología por el cognitivisimo, una corriente que identifica como clave en el comportamiento inteligente a los procesos mentales no observables directamente. 

Aunque inteligencia artificial y psicología cognitiva son nucleares a las ciencias cognitivas no son, evidentemente, las únicas disciplinas que se centran en el estudio de los mecanismos de consciencia e inteligencia que se dan en animales y máquinas. Ciertas disciplinas, como la sociología cognitiva, la pedagogía y la filosofía de la mente, entre otras, trabajan también con este rumbo aportando diferentes perspectivas y técnicas de trabajo. Se pone el énfasis en que las ciencias cognitivas asumen una naturalización materialista de sus postulados, i.e.\ no existen entidades fuera del mundo físico, por tanto la mente, el espíritu y cualquier entidad a la que pueda ser asignada la función creadora de inteligencia debe tener una manifestación física y ningún tipo de atributo no-físico. Por lo tanto, todas las disciplinas que toman parte en las construcciones de las ciencias cognitivas si no asumen esta doctrina metafísica, por así llamarla, deben compatibilizarla con ella\footnote{Es éste el caso de la psicología, cuyo estudio de los procesos mentales ha obviado tradicionalmente los procesos fisiológicos que los desencadenan.}.
\end{appendices}



\newpage

\printbibliography

\newpage
\epigraph{Grand Master Turing once dreamed that he was a machine. When he awoke he exclaimed: \\

“I don't know whether I am Turing dreaming that I am a machine, or a machine dreaming that I am Turing!”}{From the Tao of Computer Programming}

\end{document}

